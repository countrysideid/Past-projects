{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "If implemented correctly, it is easy to get over 99.2% for testing accuracy\n",
    "after a few epochs. And thre is still a lot of margin for parameter tuning,\n",
    "e.g. different initializations, decreasing learning rates when the accuracy\n",
    "stops increasing, or using model ensembling techniques, etc.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "#from sklearn import preprocessing\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# In order to speed up the convergence, we may normalize the input values\n",
    "# so that they are in the range of (0, 1) for (-1, 1)\n",
    "# Your code here.\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
    "#x_train.shape\n",
    "X_train = (x_train - np.mean(x_train, axis=1).reshape(-1,1)) / np.std(x_train, axis = 1).reshape(-1,1)\n",
    "X_train = X_train.reshape(X_train.shape[0],img_rows,img_cols,1)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
    "#x_train.shape\n",
    "X_test = (x_test - np.mean(x_test, axis=1).reshape(-1,1)) / np.std(x_test, axis = 1).reshape(-1,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],img_rows,img_cols,1)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices, e.g. \"1\" ==> [0,1,0,0,0,0,0,0,0,0]\n",
    "m_train = np.zeros([x_train.shape[0], num_classes])\n",
    "m_test = np.zeros([x_test.shape[0], num_classes])\n",
    "for i in range(y_train.shape[0]):\n",
    "    m_train[i, y_train[i]] =1\n",
    "y_train = m_train.copy()\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    m_test[i, y_test[i]] =1\n",
    "y_test = m_test.copy()\n",
    "print(y_train.shape[0], 'train samples')\n",
    "print(y_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Please build up a simple ConvNets by stacking a few conovlutioanl layers (kenel size with 3x3\n",
    "# is a good choice, don't foget using non-linear activations for convolutional layers),\n",
    "# max-pooling layers, dropout layers and dense/fully-connected layers.\n",
    "# Your code here.\n",
    "model.add(Conv2D(56,(3,3),input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(112,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(112,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(224,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# complete the loss and optimizer\n",
    "# Hints: use the cross-entropy loss, optimizer could be SGD or Adam, RMSProp, etc.\n",
    "# Feel free to try different hyper-parameters.\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 35s - loss: 1.2422 - acc: 0.5701    \n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.5367 - acc: 0.8262    \n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 35s - loss: 0.3848 - acc: 0.8772    \n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 35s - loss: 0.3171 - acc: 0.9000    \n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.2641 - acc: 0.9167    \n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.2351 - acc: 0.9256    \n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.2082 - acc: 0.9338    \n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1943 - acc: 0.9389    \n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1756 - acc: 0.9449    \n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1635 - acc: 0.9497    \n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1511 - acc: 0.9524    \n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 35s - loss: 0.1439 - acc: 0.9542    \n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 35s - loss: 0.1397 - acc: 0.9564    \n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 35s - loss: 0.1338 - acc: 0.9570    \n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1264 - acc: 0.9602    \n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 33s - loss: 0.1218 - acc: 0.9614    \n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1174 - acc: 0.9629    \n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1109 - acc: 0.9644    \n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 34s - loss: 0.1109 - acc: 0.9651    \n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 33s - loss: 0.1092 - acc: 0.9661    \n",
      "[0.056781443167128604, 0.98319999999999996]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extra Points 1: use data augmentation in the progress of model training.\n",
    "# Note that data augmentation is a practical technique for reducing overfitting.\n",
    "# Hints: you may refer to https://keras.io/preprocessing/image/\n",
    "# Your code here\n",
    "# x_train = data_augment(...)\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "model.fit_generator(datagen.flow(X_train,y_train,batch_size=32),\n",
    "                   steps_per_epoch= len(X_train)/ 32, epochs = epochs)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.1365 - acc: 0.2253     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.4130 - acc: 0.5135     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9876 - acc: 0.6671     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7800 - acc: 0.7370     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 8s - loss: 0.6546 - acc: 0.7868     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5683 - acc: 0.8119     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5162 - acc: 0.8305     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4590 - acc: 0.8464     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4050 - acc: 0.8666     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.3942 - acc: 0.8737     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3627 - acc: 0.8833     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3474 - acc: 0.8879     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3366 - acc: 0.8924     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3029 - acc: 0.9035     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.2939 - acc: 0.9074     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.2756 - acc: 0.9128     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.2699 - acc: 0.9122     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2545 - acc: 0.9186     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 8s - loss: 0.2542 - acc: 0.9206     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2474 - acc: 0.9222     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.1283 - acc: 0.2286     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.3596 - acc: 0.5349     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9490 - acc: 0.6824     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7730 - acc: 0.7464     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 8s - loss: 0.6641 - acc: 0.7810     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5777 - acc: 0.8078     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5301 - acc: 0.8292     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4900 - acc: 0.8396     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4403 - acc: 0.8583     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.4178 - acc: 0.8647     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.4028 - acc: 0.8729     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3722 - acc: 0.8822     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3536 - acc: 0.8861     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3417 - acc: 0.8911     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.3305 - acc: 0.8924     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.3022 - acc: 0.9038     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.3071 - acc: 0.8999     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2762 - acc: 0.9110     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 8s - loss: 0.2799 - acc: 0.9104     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2820 - acc: 0.9096     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 8s - loss: 2.0424 - acc: 0.2641     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.2969 - acc: 0.5532     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9290 - acc: 0.6883     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7440 - acc: 0.7535     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 9s - loss: 0.6236 - acc: 0.7958     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5615 - acc: 0.8169     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5040 - acc: 0.8406     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4498 - acc: 0.8544     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4140 - acc: 0.8659     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.3964 - acc: 0.8729     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3729 - acc: 0.8798     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3436 - acc: 0.8886     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3235 - acc: 0.8952     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3191 - acc: 0.8995     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.3049 - acc: 0.9029     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.2729 - acc: 0.9144     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.2679 - acc: 0.9165     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2621 - acc: 0.9158     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 8s - loss: 0.2628 - acc: 0.9176     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2368 - acc: 0.9246     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 8s - loss: 2.1589 - acc: 0.2163     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.4194 - acc: 0.5046     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9788 - acc: 0.6748     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7870 - acc: 0.7383     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 8s - loss: 0.6810 - acc: 0.7785     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5850 - acc: 0.8084     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5263 - acc: 0.8262     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4790 - acc: 0.8417     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4533 - acc: 0.8493     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.3942 - acc: 0.8738     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3947 - acc: 0.8743     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3796 - acc: 0.8770     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3434 - acc: 0.8911     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3369 - acc: 0.8927     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.3234 - acc: 0.8955     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.3030 - acc: 0.9017     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.2883 - acc: 0.9092     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2747 - acc: 0.9136     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 9s - loss: 0.2781 - acc: 0.9120     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2549 - acc: 0.9182     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.0137 - acc: 0.2621     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.2232 - acc: 0.5814     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.8872 - acc: 0.7014     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7163 - acc: 0.7638     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 9s - loss: 0.6319 - acc: 0.7898     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5502 - acc: 0.8219     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5028 - acc: 0.8370     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4630 - acc: 0.8493     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4289 - acc: 0.8605     \n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/468 [==============================] - 8s - loss: 0.4041 - acc: 0.8667     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3849 - acc: 0.8762     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3507 - acc: 0.8875     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3534 - acc: 0.8886     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3286 - acc: 0.8935     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.3170 - acc: 0.8983     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.3016 - acc: 0.9043     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.2937 - acc: 0.9071     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2769 - acc: 0.9120     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 9s - loss: 0.2694 - acc: 0.9126     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2730 - acc: 0.9138     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.1737 - acc: 0.2036     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.4657 - acc: 0.4859     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 9s - loss: 0.9959 - acc: 0.6617     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7993 - acc: 0.7296     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 9s - loss: 0.6786 - acc: 0.7743     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.6033 - acc: 0.8037     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 9s - loss: 0.5344 - acc: 0.8260     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4991 - acc: 0.8401     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4459 - acc: 0.8547     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.4070 - acc: 0.8715     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3932 - acc: 0.8768     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 9s - loss: 0.3675 - acc: 0.8826     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3439 - acc: 0.8898     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 9s - loss: 0.3348 - acc: 0.8913     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 9s - loss: 0.3128 - acc: 0.9011     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 9s - loss: 0.2999 - acc: 0.9045     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.2881 - acc: 0.9093     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2705 - acc: 0.9158     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 8s - loss: 0.2746 - acc: 0.9120     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2641 - acc: 0.9161     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.0707 - acc: 0.2571     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.3149 - acc: 0.5496     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9388 - acc: 0.6892     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7445 - acc: 0.7529     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 8s - loss: 0.6265 - acc: 0.8000     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5603 - acc: 0.8154     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5068 - acc: 0.8336     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4598 - acc: 0.8529     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4050 - acc: 0.8680     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.3978 - acc: 0.8737     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3628 - acc: 0.8833     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3414 - acc: 0.8897     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3310 - acc: 0.8944     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3124 - acc: 0.9026     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.2978 - acc: 0.9045     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.2897 - acc: 0.9102     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.2604 - acc: 0.9172     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2674 - acc: 0.9154     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 8s - loss: 0.2580 - acc: 0.9178     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2489 - acc: 0.9202     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.0369 - acc: 0.2669     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.2888 - acc: 0.5518     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9183 - acc: 0.6918     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7417 - acc: 0.7526     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 9s - loss: 0.6210 - acc: 0.7942     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5634 - acc: 0.8157     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 8s - loss: 0.5155 - acc: 0.8334     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4504 - acc: 0.8534     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4395 - acc: 0.8595     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.4104 - acc: 0.8695     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3770 - acc: 0.8759     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3590 - acc: 0.8845     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3391 - acc: 0.8917     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3217 - acc: 0.8971     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 8s - loss: 0.3261 - acc: 0.8961     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 8s - loss: 0.2965 - acc: 0.9034     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 8s - loss: 0.3016 - acc: 0.9038     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2779 - acc: 0.9125     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 8s - loss: 0.2706 - acc: 0.9118     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2548 - acc: 0.9191     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.0980 - acc: 0.2368     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.3437 - acc: 0.5368     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 0.9461 - acc: 0.6852     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 8s - loss: 0.7652 - acc: 0.7459     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 9s - loss: 0.6398 - acc: 0.7904     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 8s - loss: 0.5763 - acc: 0.8136     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 9s - loss: 0.5145 - acc: 0.8315     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4540 - acc: 0.8493     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 8s - loss: 0.4348 - acc: 0.8627     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.4079 - acc: 0.8683     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3659 - acc: 0.8835     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3574 - acc: 0.8859     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 9s - loss: 0.3398 - acc: 0.8915     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3191 - acc: 0.8975     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 9s - loss: 0.3112 - acc: 0.9014     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 9s - loss: 0.3033 - acc: 0.9066     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 9s - loss: 0.2704 - acc: 0.9133     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2745 - acc: 0.9128     \n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/468 [==============================] - 8s - loss: 0.2670 - acc: 0.9144     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 9s - loss: 0.2586 - acc: 0.9170     \n",
      "Epoch 1/20\n",
      "469/468 [==============================] - 9s - loss: 2.1808 - acc: 0.2054     \n",
      "Epoch 2/20\n",
      "469/468 [==============================] - 8s - loss: 1.4909 - acc: 0.4814     \n",
      "Epoch 3/20\n",
      "469/468 [==============================] - 8s - loss: 1.0400 - acc: 0.6525     \n",
      "Epoch 4/20\n",
      "469/468 [==============================] - 9s - loss: 0.8114 - acc: 0.7314     \n",
      "Epoch 5/20\n",
      "469/468 [==============================] - 8s - loss: 0.6775 - acc: 0.7755     \n",
      "Epoch 6/20\n",
      "469/468 [==============================] - 9s - loss: 0.5811 - acc: 0.8106     \n",
      "Epoch 7/20\n",
      "469/468 [==============================] - 9s - loss: 0.5152 - acc: 0.8319     \n",
      "Epoch 8/20\n",
      "469/468 [==============================] - 8s - loss: 0.4729 - acc: 0.8483     \n",
      "Epoch 9/20\n",
      "469/468 [==============================] - 9s - loss: 0.4182 - acc: 0.8635     \n",
      "Epoch 10/20\n",
      "469/468 [==============================] - 8s - loss: 0.4099 - acc: 0.8655     \n",
      "Epoch 11/20\n",
      "469/468 [==============================] - 8s - loss: 0.3646 - acc: 0.8824     \n",
      "Epoch 12/20\n",
      "469/468 [==============================] - 8s - loss: 0.3543 - acc: 0.8867     \n",
      "Epoch 13/20\n",
      "469/468 [==============================] - 8s - loss: 0.3188 - acc: 0.8954     \n",
      "Epoch 14/20\n",
      "469/468 [==============================] - 8s - loss: 0.3072 - acc: 0.9020     \n",
      "Epoch 15/20\n",
      "469/468 [==============================] - 9s - loss: 0.3108 - acc: 0.9026     \n",
      "Epoch 16/20\n",
      "469/468 [==============================] - 9s - loss: 0.2885 - acc: 0.9090     \n",
      "Epoch 17/20\n",
      "469/468 [==============================] - 9s - loss: 0.2709 - acc: 0.9126     \n",
      "Epoch 18/20\n",
      "469/468 [==============================] - 8s - loss: 0.2606 - acc: 0.9170     \n",
      "Epoch 19/20\n",
      "469/468 [==============================] - 9s - loss: 0.2485 - acc: 0.9213     \n",
      "Epoch 20/20\n",
      "469/468 [==============================] - 8s - loss: 0.2478 - acc: 0.9219     \n"
     ]
    }
   ],
   "source": [
    "# Extra Points 2: use K-Fold cross-validation for ensembling k models,\n",
    "# i.e. (1) split the whole training data into K folds;\n",
    "#      (2) train K models based on different training data;\n",
    "#      (3) when evaludating the testing data, averaging over K model predictions as final output.\n",
    "# The codes may look like:\n",
    "#   for i in range(K):\n",
    "#       x_train, y_train = ...\n",
    "#       model_i = train(x_train , y_train)\n",
    "\n",
    "#k = 10\n",
    "score = []\n",
    "\n",
    "n = np.array_split( range(x_train.shape[0]), 10)\n",
    "for i in range(10):\n",
    "    models = keras.models.clone_model(model)\n",
    "    models.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              metrics=['accuracy'])\n",
    "    x_traint = X_train[n[i], :]\n",
    "    y_traint = y_train[n[i], :]\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "    models.fit_generator(datagen.flow(X_train,y_train,batch_size=32),\n",
    "                   steps_per_epoch= len(X_train)/ batch_size, epochs = epochs)\n",
    "#    model.fit(x_traint, y_traint,\n",
    "#          batch_size=batch_size,\n",
    "#          epochs=epochs,\n",
    "#          verbose=1,\n",
    "#          validation_data=(x_test, y_test))\n",
    "    score.append( models.evaluate(X_test, y_test, verbose=0))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.124701137907\n",
      "Test accuracy: 0.96165\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "for i in range(10):\n",
    "    loss = loss+score[i][0]\n",
    "loss=loss/10\n",
    "accu = 0\n",
    "for i in range(10):\n",
    "    accu = accu+score[i][1]\n",
    "accu=accu/10\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
